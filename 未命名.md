## 1.基于MNIST 数据集的自编码器实现

#### (1) 完成数据读写并试着搭建深度自编码器网络。

数据读取

```python
data_tf = transforms.Compose([transforms.ToTensor()])
train_dataset = datasets.MNIST(root='\MNIST_data', train=True, transform=data_tf, download=False)
test_dataset = datasets.MNIST(root='\MNIST_data', train=False, transform=data_tf, download=False)
train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)
test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)
```

搭建自编码器网络

```python
class autoencoder(nn.Module):
    def __init__(self):
        super(autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(1, 8, 3, stride=2, padding=1),
            nn.ReLU(True),
            nn.Conv2d(8, 16, 3, stride=2, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(True),
            nn.Conv2d(16, 32, 3, stride=2, padding=0),
            nn.ReLU(True),
            nn.Flatten(start_dim=1)
        )
        self.encoder_lin = nn.Sequential(
            nn.Linear(32*3*3,64),
            nn.Linear(64,2)
        )
        self.decoder = nn.Sequential(
            nn.Unflatten(dim=1, unflattened_size=(32, 3, 3)),
            nn.ConvTranspose2d(32, 16, 3, stride=2, output_padding=0),
            nn.BatchNorm2d(16),
            nn.ReLU(True),
            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(8),
            nn.ReLU(True),
            nn.ConvTranspose2d(8, 1, 3, stride=2, padding=1, output_padding=1),
            nn.Sigmoid()
        )
        self.decoder_lin = nn.Sequential(
            nn.Linear(2,64),
            nn.Linear(64,32*3*3)
        )
    def forward(self, x):
        x = self.encoder(x)
        encode = self.encoder_lin(x)
        x = self.decoder_lin(encode)
        decode = self.decoder(x)
        return encode, decode
```

#### (2) 选择二元交叉熵函数作为损失函数，在限制bottleneck 层维度为2 的情况下训练模型。

设置二元交叉熵函数为损失函数

```python
criterion = nn.BCELoss()
```

限制bottleneck 层维度为2

```python
self.encoder_lin = nn.Sequential(
            nn.Linear(32*3*3,64),
            nn.Linear(64,2)
        )
```

训练模型

```python
for i in range(epoch):
    for img,label in train_loader:
        img = img.to(device)
        # forward
        _, output = model(img)
        loss = criterion(output, img)
        # backward
        optimizier.zero_grad()
        loss.backward()
        optimizier.step()
    if (i+1) % 5 == 0:
        print("epoch: {}, loss is {}".format((i+1), loss.data))
torch.save(model, './autoencoder.pth')
```



#### (3) 设置噪声因子为0.4，在输入图像上叠加均值为0 且方差为1 的标准高斯白噪声，训练降噪自编码器，并进行降噪结果展示。

编写一个函数用于添加噪声

```python
# 加噪声
def add_noise(input, noise_factor):
    x = np.array(input,dtype=np.float32)
    x_train_noisy = x + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x.shape)
    x_train_noisy = np.array(x_train_noisy,dtype=np.float32)
    train = torch.from_numpy(x_train_noisy)
    return train
```

再训练时，我们对每个批次的数据添加噪声，并使用原始数据与输出计算损失。

```python
model.train()
for i in range(epoch):
    for img, label in train_loader:
        img_noise = add_noise(img, 0.4)
        img = img.to(device)
        img_noise = img_noise.to(device)
        # forward
        _, output = model(img_noise)
        loss = criterion(output,img)
        # backward
        optimizier.zero_grad()
        loss.backward()
        optimizier.step()
    if (i+1) % 5 == 0:
        print("epoch: {}, loss is {:.4f}".format((i+1), loss.data))
torch.save(model, './autoencoder_noisy.pth')
```

训练完成后在测试集上观察效果。

```python
model.eval()
with torch.no_grad():
    i = 0
    for img, _ in test_loader:
        if i <= 10:
            img_noise = add_noise(img, 0.4)
            img = img.to(device)
            img_noise = img_noise.to(device)
            # forward
            _, output = model(img_noise)
            plt.subplot(3,11,i+1)
            plt.imshow(img[0][0].to('cpu'),cmap='gist_gray')
            plt.axis(False)
            plt.subplot(3,11,i+12)
            plt.imshow(img_noise[0][0].to('cpu'),cmap='gist_gray')
            plt.axis(False)
            plt.subplot(3,11,i+23)
            plt.imshow(output[0][0].to('cpu'),cmap='gist_gray')
            plt.axis(False)
        i += 1 
plt.show()
```

输出十一张原图、加噪声后、降噪结果。

![output7](C:\Users\21418\Desktop\课程\神经网络与深度学习\实验三\实验三-材料\output.png)

效果还是很不错的。

#### (4) 试在问题(2)的基础上，对latent code 进行均匀采样，并利用解码器对采样结果进行恢复，观察并描述所得到的结果.

latent code在[-1，1]上均匀采样

```python
x = np.random.uniform(-1,1,20)
y = np.random.uniform(-1,1,20)
```

将这些样本输入到解码器中

```python
k = 1
with torch.no_grad():
    for i in x:
        for j in y:
            h = np.array([[i, j]],dtype=np.float32)
            a = decoder1(torch.from_numpy(h))
            plt.subplot(20,20,k)
            plt.imshow(a[0][0],cmap='gist_gray')
            plt.axis(False)
            k+=1
    plt.show()
```

输出结果。

![output5](C:\Users\21418\Desktop\课程\神经网络与深度学习\实验三\实验三-材料\output14.png)

大部分手写数字被还原出来了，而且还原的效果很好。

#### (5) 试在问题(4)的基础上，在训练深度自编码器时使用L2 正则化，观察并描述你所得到的结果。

使用L2正则化需要在优化器中设置`weight_decay`参数，这里设置为0.00005

```python
optimizier = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.00005)
```

重复（4）中的过程，观察结果。

![output6](C:\Users\21418\Desktop\课程\神经网络与深度学习\实验三\实验三-材料\output15.png)

好像效果变差了，能够显示出来的数字变少了。

## 2.隐空间特性探究

#### (1) 若记输入图像为$x$，则$c$ 和$\hat{x}$分别表示由encoder 编码得到的latent code 和由decoder 重建得到的输出图像。请以下图结构为参考，以MSE 作为损失函数，设置$c$ 的维度为8 × 8 × 16，搭建并训练深度自编码器网络。

先读取数据，为了简化计算统一把所有图片大小调至`32*32*3`。

```python
data_tf = transforms.Compose([
    transforms.Resize((32,32)),
    transforms.ToTensor()
])
data = datasets.ImageFolder('Stanford Dogs Dataset_datasets/Stanford Dogs Dataset_images_datasets/Images',transform=data_tf)
train_loader = DataLoader(data, shuffle=False, batch_size=batch_size)
```

搭建自编码器网络,`latent code`的`shape`为`（8, 8, 16）`

```python
class autoencoder(nn.Module):
    def __init__(self):
        super(autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Conv2d(3, 8, 3, stride=2, padding=1),
            nn.ReLU(),
            nn.Conv2d(8, 16, 3, stride=2, padding=1),
            nn.BatchNorm2d(16),
            nn.ReLU(),
        )
        self.decoder = nn.Sequential(
            nn.ConvTranspose2d(16, 8, 3, stride=2, padding=1, output_padding=1),
            nn.BatchNorm2d(8),
            nn.ReLU(),
            nn.ConvTranspose2d(8, 3, 3, stride=2, padding=1, output_padding=1),
        )
    def forward(self, x):
        encode = self.encoder(x)
        decode = self.decoder(encode)
        return encode, decode
```

设置损失函数和优化器

```python
criterion = nn.MSELoss()
optimizier = torch.optim.Adam(model.parameters(), lr=lr)
```

开始训练

```python
model.train()
for i in range(epoch):
    for img, label in train_loader:
        img = img.to(device)
        # forward
        encode, decode = model(img)
        loss = criterion(decode,img)
        # backward
        optimizier.zero_grad()
        loss.backward()
        optimizier.step()
    print("epoch: {}, loss is {:.4f}".format((i+1), loss.data))
torch.save(model.state_dict(), './autoencoder2.pth')
```

#### (2) 随机选取9 张图片，分别展示每一张图片的原图和重建图像，并对latent code 进行可视化。

用于可视化的代码如下，这里的九张图片为在`batch_size`为512情况下的前九个批次中每个批次的第一张图片。

latent code我将其从3维展平为2维后显示。

```python
model.eval()
with torch.no_grad():
    i = 0
    for img, _ in train_loader:
        if i <= 9:
            img = img.to(device)
            # forward
            latent, output = model(img)
            plt.subplot(3,9,i+1)
            old_img = transforms.ToPILImage()(img[0].to('cpu')).convert('RGB')
            plt.imshow(old_img)
            plt.axis(False)
            plt.subplot(3,9,i+10)
            plt.imshow(np.array(latent[0].to('cpu')).reshape([32,32]))
            plt.axis(False)
            plt.subplot(3,9,i+19)
            new_img = transforms.ToPILImage()(output[0].to('cpu')).convert('RGB')
            plt.imshow(new_img)
            plt.axis(False)
        i += 1 
        if i == 9:
            break
plt.show()
```

输出结果如下：

![output5](C:\Users\21418\Desktop\课程\神经网络与深度学习\实验三\实验三-材料\output2.png)

#### (3) 随机选取256 张图片，通过所构造的自编码器网络中的encoder得到其对应的latent code。计算这些latent code的统计特性，并以此为参数构造高斯分布。试在你所得到的高斯分布上进行9 次随机采样，再将采样得到的9组latent code送入decoder，观察所得到的图像并描述你观察到的现象。

随机选取256张图片，先从数据集范围内生成256个不重复的整数。

```python
rd = np.random.RandomState(888) 
# 随机整数
matrix = np.sort(rd.choice(20580, 256, replace=False))
```

然后计算这256张图片的latent code

```python
model.eval()
k = 0
i = 0
latent_list = []
with torch.no_grad():
    for img, _ in train_loader:
        if i == matrix[k]:
            k += 1
            img = img.to(device)
            # forward
            latent, output = model(img)
            latent_list.append(np.array(latent.to('cpu')))
        i += 1
        if k == 256:
            break
```

latent code的纬度为8\*8\*16，我将其看做1024元高斯分布,计算这些数据的均值和协方差，然后在高斯分布上随机取9个样本

```python
latent_list = np.array(latent_list)[:,0,:,:,:]
latent_array = np.array(latent_list).reshape([256,-1]).T
latent_mean = np.mean(latent_array,axis=1)
latent_cov = np.cov(latent_array)
latent_rand = rd.multivariate_normal(latent_mean,latent_cov,size=9).reshape([9,1,16,8,8])
latent_rand = np.array(latent_rand,dtype=np.float32)
```

对这些样本解码。

```python
with torch.no_grad():
    for i in range(9):
        a = decoder1(torch.from_numpy(latent_rand[i]))
        plt.subplot(1,9,i+1)
        img = transforms.ToPILImage()(a[0]).convert('RGB')
        plt.imshow(img)
        plt.axis(False)
    plt.show()
```

得到结果如下图所示。

![output5](C:\Users\21418\Desktop\课程\神经网络与深度学习\实验三\实验三-材料\output3.png)

虽然有点模糊，但是基本能看出来是狗，和（2）中的图片风格很相似。

#### (4) 在任务(3)的基础上，在这9 张图片的latent code 上叠加随机的高斯噪声扰动，观察叠加噪声后的latent code 送入decoder 生成的图像，并解释你观察到的现象。

仿照1题中的方法添加噪声，噪声因子为0.1.

![output5](C:\Users\21418\Desktop\课程\神经网络与深度学习\实验三\实验三-材料\output4.png)

图像总体变化不大，说明受噪声影响较小，可能是模型稳定性较好，也可能是因为噪声较小。

#### (5) 如下图所示，请将latent code叠加零均值高斯噪声作为一类正则自编码器方法，由此带噪训练新的正则自编码器(限制latent code维度为8 × 8 × 16)。需要注意的是，为了保证高斯噪声具有稳定的效果，还需要在叠加噪声前对latent code进行功率归一化。请在噪声方差分别为0.05，0.1，0.15 时，给出Dog 数据集上重建图像PSNR的平均值，需要并探究此时从latent space采样是否有生成效果。

我对`add_noise.py`进行了稍微修改，这样我们在实例化add_noise时就可以直接用方差了。

```python
class add_noise(nn.Module):
    def __init__(self, s):
        super(add_noise, self).__init__()
        self.std = pow(s, 1/2)  # 标准差
```

添加到网络结构中

```python
        self.addno = add_noise(0.05)
    def forward(self, x):
        encode = self.encoder(x)
        x = self.addno(encode)
        decode = self.decoder(x)
        return encode, decode
```

然后分别取方差为`[0.05, 0.1, 0.15]`进行训练。

训练完成后，我们获取数据集上的原图像`img_list`和重建图像`decode_list`，用于后续计算。

```python
model.eval()
with torch.no_grad():
    decode_list =[]
    img_list = []
    for img, label in train_loader:
        img_list.append(np.array(img))
        img = img.to(device)
        # forward
        encode, decode = model(img)
        decode_list.append(np.array(decode.to('cpu')))
    decode_list = np.array(decode_list)
    img_list = np.array(img_list)
    decode_list = decode_list[:,0,:,:,:]
```

先计算MSE再计算PSNR。

```python
img_list = img_list[:,0,:,:,:]
x = torch.from_numpy(decode_list)
y = torch.from_numpy(img_list)
mse = distortion.MSE()
MSE = mse(x,y)
PSNR = MSE2PSNR(MSE)
```

得到的结果如下表。

| 噪声方差 | PSNR              |
| -------- | ----------------- |
| 0.05     | 72.8567462017939  |
| 0.1      | 73.60428751803731 |
| 0.15     | 72.54542083465417 |

